{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANOJ KUMAR - 2048015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from itertools import repeat\n",
    "import multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "class CustomKNN:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.accurate_predictions = 0\n",
    "        self.total_predictions = 0\n",
    "        self.accuracy = 0.0\n",
    "\n",
    "    def predict(self, training_data, to_predict, k = 3):\n",
    "        if len(training_data) >= k:\n",
    "            print(\"K cannot be smaller than the total voting groups(ie. number of training data points)\")\n",
    "            return\n",
    "\n",
    "        distributions = []\n",
    "        for group in training_data:\n",
    "            for features in training_data[group]:\n",
    "                #Calculate Euclidean distance\n",
    "                euclidean_distance = np.linalg.norm(np.array(features)- np.array(to_predict))\n",
    "                distributions.append([euclidean_distance, group])\n",
    "        #Find the class of K nearest points\n",
    "        results = [i[1] for i in sorted(distributions)[:k]]\n",
    "        result = Counter(results).most_common(1)[0][0]\n",
    "        confidence = Counter(results).most_common(1)[0][1]/k\n",
    "\n",
    "        return result, to_predict\n",
    "\n",
    "    def test(self, test_set, training_set):\n",
    "        pool = mp.Pool(processes= 8)\n",
    "\n",
    "        arr = {}\n",
    "        s = time.time()\n",
    "        # 'Parallelization' happens here\n",
    "        for group in test_set:\n",
    "            arr[group] =  pool.starmap(self.predict, zip(repeat(training_set), test_set[group], repeat(3)))\n",
    "        e = time.time()\n",
    "\n",
    "        #Calculating Accuracy\n",
    "        for group in test_set:\n",
    "            for data in test_set[group]:\n",
    "                for i in arr[group]:\n",
    "                    if data == i[1]:\n",
    "                        self.total_predictions += 1\n",
    "                        #If accuracte -> predicted class = original class\n",
    "                        if group == i[0]:\n",
    "                            self.accurate_predictions+=1\n",
    "\n",
    "        self.accuracy = 100*(self.accurate_predictions/self.total_predictions)\n",
    "        print(\"\\nAcurracy :\", str(self.accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_data(df):\n",
    "\n",
    "    df.replace('?', -999999, inplace = True)\n",
    "\n",
    "    df.replace('yes', 4, inplace = True)\n",
    "    df.replace('no', 2, inplace = True)\n",
    "\n",
    "    df.replace('notpresent', 4, inplace = True)\n",
    "    df.replace('present', 2, inplace = True)\n",
    "\n",
    "    df.replace('abnormal', 4, inplace = True)\n",
    "    df.replace('normal', 2, inplace = True)\n",
    "\n",
    "    df.replace('poor', 4, inplace = True)\n",
    "    df.replace('good', 2, inplace = True)\n",
    "\n",
    "    df.replace('ckd', 4, inplace = True)\n",
    "    df.replace('notckd', 2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Load the dataset\n",
    "    df = pd.read_csv(r\"chronic_kidney_disease.csv\")\n",
    "    mod_data(df)\n",
    "    dataset = df.astype(float).values.tolist()\n",
    "\n",
    "    #Normalize the data\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled) #Replace df with normalized values\n",
    "\n",
    "    #Shuffle the dataset\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    #10% of the available data will be used for testing\n",
    "    test_size = 0.1\n",
    "\n",
    "    #The keys of the dict are the classes that the data is classfied into\n",
    "    training_set = {2: [], 4:[]}\n",
    "    test_set = {2: [], 4:[]}\n",
    "\n",
    "    #Split data into training and test for cross validation\n",
    "    training_data = dataset[:-int(test_size * len(dataset))]\n",
    "    test_data = dataset[-int(test_size * len(dataset)):]\n",
    "\n",
    "    #Insert data into the training set\n",
    "    for record in training_data:\n",
    "        training_set[record[-1]].append(record[:-1]) # Append the list in the dict will all the elements of the record except the class\n",
    "\n",
    "    #Insert data into the test set\n",
    "    for record in test_data:\n",
    "        test_set[record[-1]].append(record[:-1]) # Append the list in the dict will all the elements of the record except the class\n",
    "\n",
    "    s = time.time()\n",
    "    knn = CustomKNN()\n",
    "    knn.test(test_set, training_set)\n",
    "    e = time.time()\n",
    "\n",
    "    # print(\"Exec Time: \", e-s)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
