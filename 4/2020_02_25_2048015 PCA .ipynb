{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><h2><b><center>MANOJ KUMAR - 2048015</b></h2></div>\n",
    "<div><h2><b><center>PCA v/s LDA - Chronic Kidney Disease</b></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Dataset & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              400 non-null    int64  \n",
      " 1   age             391 non-null    float64\n",
      " 2   bp              388 non-null    float64\n",
      " 3   sg              353 non-null    float64\n",
      " 4   al              354 non-null    float64\n",
      " 5   su              351 non-null    float64\n",
      " 6   rbc             248 non-null    object \n",
      " 7   pc              335 non-null    object \n",
      " 8   pcc             396 non-null    object \n",
      " 9   ba              396 non-null    object \n",
      " 10  bgr             356 non-null    float64\n",
      " 11  bu              381 non-null    float64\n",
      " 12  sc              383 non-null    float64\n",
      " 13  sod             313 non-null    float64\n",
      " 14  pot             312 non-null    float64\n",
      " 15  hemo            348 non-null    float64\n",
      " 16  pcv             330 non-null    object \n",
      " 17  wc              295 non-null    object \n",
      " 18  rc              270 non-null    object \n",
      " 19  htn             398 non-null    object \n",
      " 20  dm              398 non-null    object \n",
      " 21  cad             398 non-null    object \n",
      " 22  appet           399 non-null    object \n",
      " 23  pe              399 non-null    object \n",
      " 24  ane             399 non-null    object \n",
      " 25  classification  400 non-null    object \n",
      "dtypes: float64(11), int64(1), object(14)\n",
      "memory usage: 81.4+ KB\n"
     ]
    }
   ],
   "source": [
    "kidney_disease = pd.read_csv(\"kidney_disease.csv\")\n",
    "kidney_disease.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were exploring the metadata of our dataset.\n",
    "   - 25 columns with int, float, and Object datatypes\n",
    "   - Some of the features do having Null values, so data preprocessing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sg</th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc</th>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba</th>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bgr</th>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>410</td>\n",
       "      <td>138</td>\n",
       "      <td>70</td>\n",
       "      <td>490</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bu</th>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>107</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemo</th>\n",
       "      <td>15.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcv</th>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc</th>\n",
       "      <td>7800</td>\n",
       "      <td>6000</td>\n",
       "      <td>7500</td>\n",
       "      <td>6700</td>\n",
       "      <td>7300</td>\n",
       "      <td>7800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6900</td>\n",
       "      <td>9600</td>\n",
       "      <td>12100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rc</th>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>htn</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cad</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appet</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ane</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           1           2           3           4  \\\n",
       "id                       0           1           2           3           4   \n",
       "age                     48           7          62          48          51   \n",
       "bp                      80          50          80          70          80   \n",
       "sg                    1.02        1.02        1.01       1.005        1.01   \n",
       "al                       1           4           2           4           2   \n",
       "su                       0           0           3           0           0   \n",
       "rbc                    NaN         NaN      normal      normal      normal   \n",
       "pc                  normal      normal      normal    abnormal      normal   \n",
       "pcc             notpresent  notpresent  notpresent     present  notpresent   \n",
       "ba              notpresent  notpresent  notpresent  notpresent  notpresent   \n",
       "bgr                    121         NaN         423         117         106   \n",
       "bu                      36          18          53          56          26   \n",
       "sc                     1.2         0.8         1.8         3.8         1.4   \n",
       "sod                    NaN         NaN         NaN         111         NaN   \n",
       "pot                    NaN         NaN         NaN         2.5         NaN   \n",
       "hemo                  15.4        11.3         9.6        11.2        11.6   \n",
       "pcv                     44          38          31          32          35   \n",
       "wc                    7800        6000        7500        6700        7300   \n",
       "rc                     5.2         NaN         NaN         3.9         4.6   \n",
       "htn                    yes          no          no         yes          no   \n",
       "dm                     yes          no         yes          no          no   \n",
       "cad                     no          no          no          no          no   \n",
       "appet                 good        good        poor        poor        good   \n",
       "pe                      no          no          no         yes          no   \n",
       "ane                     no          no         yes         yes          no   \n",
       "classification         ckd         ckd         ckd         ckd         ckd   \n",
       "\n",
       "                         5           6           7           8           9  \\\n",
       "id                       5           6           7           8           9   \n",
       "age                     60          68          24          52          53   \n",
       "bp                      90          70         NaN         100          90   \n",
       "sg                   1.015        1.01       1.015       1.015        1.02   \n",
       "al                       3           0           2           3           2   \n",
       "su                       0           0           4           0           0   \n",
       "rbc                    NaN         NaN      normal      normal    abnormal   \n",
       "pc                     NaN      normal    abnormal    abnormal    abnormal   \n",
       "pcc             notpresent  notpresent  notpresent     present     present   \n",
       "ba              notpresent  notpresent  notpresent  notpresent  notpresent   \n",
       "bgr                     74         100         410         138          70   \n",
       "bu                      25          54          31          60         107   \n",
       "sc                     1.1          24         1.1         1.9         7.2   \n",
       "sod                    142         104         NaN         NaN         114   \n",
       "pot                    3.2           4         NaN         NaN         3.7   \n",
       "hemo                  12.2        12.4        12.4        10.8         9.5   \n",
       "pcv                     39          36          44          33          29   \n",
       "wc                    7800         NaN        6900        9600       12100   \n",
       "rc                     4.4         NaN           5         4.0         3.7   \n",
       "htn                    yes          no          no         yes         yes   \n",
       "dm                     yes          no         yes         yes         yes   \n",
       "cad                     no          no          no          no          no   \n",
       "appet                 good        good        good        good        poor   \n",
       "pe                     yes          no         yes          no          no   \n",
       "ane                     no          no          no         yes         yes   \n",
       "classification         ckd         ckd         ckd         ckd         ckd   \n",
       "\n",
       "                        10          11  \n",
       "id                      10          11  \n",
       "age                     50          63  \n",
       "bp                      60          70  \n",
       "sg                    1.01        1.01  \n",
       "al                       2           3  \n",
       "su                       4           0  \n",
       "rbc                    NaN    abnormal  \n",
       "pc                abnormal    abnormal  \n",
       "pcc                present     present  \n",
       "ba              notpresent  notpresent  \n",
       "bgr                    490         380  \n",
       "bu                      55          60  \n",
       "sc                       4         2.7  \n",
       "sod                    NaN         131  \n",
       "pot                    NaN         4.2  \n",
       "hemo                   9.4        10.8  \n",
       "pcv                     28          32  \n",
       "wc                     NaN        4500  \n",
       "rc                     NaN         3.8  \n",
       "htn                    yes         yes  \n",
       "dm                     yes         yes  \n",
       "cad                     no          no  \n",
       "appet                 good        poor  \n",
       "pe                      no         yes  \n",
       "ane                    yes          no  \n",
       "classification         ckd         ckd  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_disease.head(12).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are transforming the data frame to help to get all the features vertically.\n",
    "        \n",
    "   - The collection of numerical and categorical values are seen.\n",
    "   - 'rc','wc', and 'pcv' needs to be updated to float from Object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '?' character remove process in the dataset\n",
    "for i in ['rc','wc','pcv']:\n",
    "    kidney_disease[i] = kidney_disease[i].str.extract('(\\d+)').astype(float)\n",
    "    \n",
    "    \n",
    "# Filling missing numeric data in the dataset with mean\n",
    "for i in ['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','rc','wc','pcv']:\n",
    "    kidney_disease[i].fillna(kidney_disease[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tab spaces in the data\n",
    "kidney_disease['dm'] = kidney_disease['dm'].replace(to_replace={'\\tno':'no','\\tyes':'yes',' yes':'yes'}) \n",
    "kidney_disease['cad'] = kidney_disease['cad'].replace(to_replace='\\tno',value='no') \n",
    "kidney_disease['classification'] = kidney_disease['classification'].replace(to_replace='ckd\\t',value='ckd')\n",
    "\n",
    "# Mapping the text to 1/0 and cleaning the dataset \n",
    "kidney_disease[['htn','dm','cad','pe','ane']] = kidney_disease[['htn','dm','cad','pe','ane']].replace(to_replace={'yes':1,'no':0})\n",
    "kidney_disease[['rbc','pc']] = kidney_disease[['rbc','pc']].replace(to_replace={'abnormal':1,'normal':0})\n",
    "kidney_disease[['pcc','ba']] = kidney_disease[['pcc','ba']].replace(to_replace={'present':1,'notpresent':0})\n",
    "kidney_disease[['appet']] = kidney_disease[['appet']].replace(to_replace={'good':1,'poor':0})\n",
    "kidney_disease['classification'] = kidney_disease['classification'].replace(to_replace={'ckd':1,'notckd':0})\n",
    "\n",
    "kidney_disease.rename(columns={'classification':'class'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     400 non-null    float64\n",
      " 1   bp      400 non-null    float64\n",
      " 2   sg      400 non-null    float64\n",
      " 3   al      400 non-null    float64\n",
      " 4   su      400 non-null    float64\n",
      " 5   rbc     248 non-null    float64\n",
      " 6   pc      335 non-null    float64\n",
      " 7   pcc     396 non-null    float64\n",
      " 8   ba      396 non-null    float64\n",
      " 9   bgr     400 non-null    float64\n",
      " 10  bu      400 non-null    float64\n",
      " 11  sc      400 non-null    float64\n",
      " 12  sod     400 non-null    float64\n",
      " 13  pot     400 non-null    float64\n",
      " 14  hemo    400 non-null    float64\n",
      " 15  pcv     400 non-null    float64\n",
      " 16  wc      400 non-null    float64\n",
      " 17  rc      400 non-null    float64\n",
      " 18  htn     398 non-null    float64\n",
      " 19  dm      398 non-null    float64\n",
      " 20  cad     398 non-null    float64\n",
      " 21  appet   399 non-null    float64\n",
      " 22  pe      399 non-null    float64\n",
      " 23  ane     399 non-null    float64\n",
      " 24  class   400 non-null    int64  \n",
      "dtypes: float64(24), int64(1)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "kidney_disease.drop('id',axis=1,inplace=True)\n",
    "kidney_disease.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are customizing our features based on the pre-knowledge taken from the previous lab.\n",
    "    \n",
    "   - Value error \n",
    "   - Datatype error\n",
    "   - Dropping unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>53.00</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>76.469072</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sg</th>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bgr</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>148.036517</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>70.00</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>380.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bu</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>107.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc</th>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>7.20</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sod</th>\n",
       "      <td>137.528754</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>111.000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>142.000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>114.00</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>131.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pot</th>\n",
       "      <td>4.627244</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>3.200</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemo</th>\n",
       "      <td>15.400000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>11.200</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>12.200</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcv</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>29.00</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc</th>\n",
       "      <td>7800.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>6700.000</td>\n",
       "      <td>7300.000000</td>\n",
       "      <td>7800.000</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>9600.000000</td>\n",
       "      <td>12100.00</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>4500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rc</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.241636</td>\n",
       "      <td>4.241636</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.241636</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.241636</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>htn</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cad</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appet</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ane</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2         3            4         5  \\\n",
       "age      48.000000     7.000000    62.000000    48.000    51.000000    60.000   \n",
       "bp       80.000000    50.000000    80.000000    70.000    80.000000    90.000   \n",
       "sg        1.020000     1.020000     1.010000     1.005     1.010000     1.015   \n",
       "al        1.000000     4.000000     2.000000     4.000     2.000000     3.000   \n",
       "su        0.000000     0.000000     3.000000     0.000     0.000000     0.000   \n",
       "rbc       0.000000     0.000000     0.000000     0.000     0.000000     0.000   \n",
       "pc        0.000000     0.000000     0.000000     1.000     0.000000     0.000   \n",
       "pcc       0.000000     0.000000     0.000000     1.000     0.000000     0.000   \n",
       "ba        0.000000     0.000000     0.000000     0.000     0.000000     0.000   \n",
       "bgr     121.000000   148.036517   423.000000   117.000   106.000000    74.000   \n",
       "bu       36.000000    18.000000    53.000000    56.000    26.000000    25.000   \n",
       "sc        1.200000     0.800000     1.800000     3.800     1.400000     1.100   \n",
       "sod     137.528754   137.528754   137.528754   111.000   137.528754   142.000   \n",
       "pot       4.627244     4.627244     4.627244     2.500     4.627244     3.200   \n",
       "hemo     15.400000    11.300000     9.600000    11.200    11.600000    12.200   \n",
       "pcv      44.000000    38.000000    31.000000    32.000    35.000000    39.000   \n",
       "wc     7800.000000  6000.000000  7500.000000  6700.000  7300.000000  7800.000   \n",
       "rc        5.000000     4.241636     4.241636     3.000     4.000000     4.000   \n",
       "htn       1.000000     0.000000     0.000000     1.000     0.000000     1.000   \n",
       "dm        1.000000     0.000000     1.000000     0.000     0.000000     1.000   \n",
       "cad       0.000000     0.000000     0.000000     0.000     0.000000     0.000   \n",
       "appet     1.000000     1.000000     0.000000     0.000     1.000000     1.000   \n",
       "pe        0.000000     0.000000     0.000000     1.000     0.000000     1.000   \n",
       "ane       0.000000     0.000000     1.000000     1.000     0.000000     0.000   \n",
       "class     1.000000     1.000000     1.000000     1.000     1.000000     1.000   \n",
       "\n",
       "                 6            7            8         9           10       11  \n",
       "age      68.000000    24.000000    52.000000     53.00    50.000000    63.00  \n",
       "bp       70.000000    76.469072   100.000000     90.00    60.000000    70.00  \n",
       "sg        1.010000     1.015000     1.015000      1.02     1.010000     1.01  \n",
       "al        0.000000     2.000000     3.000000      2.00     2.000000     3.00  \n",
       "su        0.000000     4.000000     0.000000      0.00     4.000000     0.00  \n",
       "rbc       0.000000     0.000000     0.000000      1.00     0.000000     1.00  \n",
       "pc        0.000000     1.000000     1.000000      1.00     1.000000     1.00  \n",
       "pcc       0.000000     0.000000     1.000000      1.00     1.000000     1.00  \n",
       "ba        0.000000     0.000000     0.000000      0.00     0.000000     0.00  \n",
       "bgr     100.000000   410.000000   138.000000     70.00   490.000000   380.00  \n",
       "bu       54.000000    31.000000    60.000000    107.00    55.000000    60.00  \n",
       "sc       24.000000     1.100000     1.900000      7.20     4.000000     2.70  \n",
       "sod     104.000000   137.528754   137.528754    114.00   137.528754   131.00  \n",
       "pot       4.000000     4.627244     4.627244      3.70     4.627244     4.20  \n",
       "hemo     12.400000    12.400000    10.800000      9.50     9.400000    10.80  \n",
       "pcv      36.000000    44.000000    33.000000     29.00    28.000000    32.00  \n",
       "wc     8406.122449  6900.000000  9600.000000  12100.00  8406.122449  4500.00  \n",
       "rc        4.241636     5.000000     4.000000      3.00     4.241636     3.00  \n",
       "htn       0.000000     0.000000     1.000000      1.00     1.000000     1.00  \n",
       "dm        0.000000     1.000000     1.000000      1.00     1.000000     1.00  \n",
       "cad       0.000000     0.000000     0.000000      0.00     0.000000     0.00  \n",
       "appet     1.000000     1.000000     1.000000      0.00     1.000000     0.00  \n",
       "pe        0.000000     1.000000     0.000000      0.00     0.000000     1.00  \n",
       "ane       0.000000     0.000000     1.000000      1.00     1.000000     0.00  \n",
       "class     1.000000     1.000000     1.000000      1.00     1.000000     1.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling the missing string data as the most repetitive (mod)\n",
    "kidney_disease=kidney_disease.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "\n",
    "features = kidney_disease.keys()\n",
    "kidney_disease.head(12).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the missing string data as the most repetitive (mod)\n",
    "\n",
    "\n",
    "### Pre-processed final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = kidney_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component Analysis - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributing the dataset into two components X and Y \n",
    "X = dataset.iloc[:, 0:24].values \n",
    "y = dataset.iloc[:, 24].values \n",
    "\n",
    "# Splitting the X and Y into the Training set and Testing set \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 0 to 23th column taken as X \n",
    "   - Classification(Target) feature taken as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing preprocessing part \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "\n",
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Normalization\n",
    "  \n",
    "Applying PCA function on training and testing set of X component "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28935568, 0.07469401])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying PCA function on training and testing set of X component \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "pca = PCA(n_components = 2) \n",
    "\n",
    "X_train = pca.fit_transform(X_train) \n",
    "X_test = pca.transform(X_test) \n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_ \n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression To the training set \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "Logistic_Regression = LogisticRegression(random_state = 0) \n",
    "Logistic_Regression.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0],\n",
       "       [ 1, 51]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set result using predict function under LogisticRegression \n",
    "Log_pred = Logistic_Regression.predict(X_test) \n",
    "\n",
    "# making confusion matrix between test set of Y and predicted value. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "LogisticRegression_confusion_matrix = confusion_matrix(y_test, Log_pred) \n",
    "LogisticRegression_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the training set \n",
    "# result through scatter plot \n",
    "from matplotlib.colors import ListedColormap \n",
    "\n",
    "X_set, y_set = X_train, y_train \n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n",
    "                    stop = X_set[:, 0].max() + 1, step = 0.01), \n",
    "                    np.arange(start = X_set[:, 1].min() - 1, \n",
    "                    stop = X_set[:, 1].max() + 1, step = 0.01)) \n",
    "\n",
    "plt.contourf(X1, X2, Logistic_Regression.predict(np.array([X1.ravel(), \n",
    "            X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, \n",
    "            cmap = ListedColormap(('aquamarine', 'white', 'yellow'))) \n",
    "\n",
    "plt.xlim(X1.min(), X1.max()) \n",
    "plt.ylim(X2.min(), X2.max()) \n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)): \n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], \n",
    "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j) \n",
    "\n",
    "plt.title('Logistic Regression (Training set)') \n",
    "plt.xlabel('PC1') # for Xlabel \n",
    "plt.ylabel('PC2') # for Ylabel \n",
    "plt.legend() # to show legend \n",
    "\n",
    "# show scatter plot \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results through scatter plot \n",
    "from matplotlib.colors import ListedColormap \n",
    "\n",
    "X_set, y_set = X_test, y_test \n",
    "\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n",
    "                    stop = X_set[:, 0].max() + 1, step = 0.01), \n",
    "                    np.arange(start = X_set[:, 1].min() - 1, \n",
    "                    stop = X_set[:, 1].max() + 1, step = 0.01)) \n",
    "\n",
    "plt.contourf(X1, X2, Logistic_Regression.predict(np.array([X1.ravel(), \n",
    "            X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, \n",
    "            cmap = ListedColormap(('aquamarine', 'white', 'yellow'))) \n",
    "\n",
    "plt.xlim(X1.min(), X1.max()) \n",
    "plt.ylim(X2.min(), X2.max()) \n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)): \n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], \n",
    "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j) \n",
    "\n",
    "# title for scatter plot \n",
    "plt.title('Logistic Regression (Test set)') \n",
    "plt.xlabel('PC1') # for Xlabel \n",
    "plt.ylabel('PC2') # for Ylabel \n",
    "plt.legend() \n",
    "\n",
    "# show scatter plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.0125\n",
      "MSE:  0.0125\n",
      "RMSE:  0.11180339887498948\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "print(\"MAE: \",metrics.mean_absolute_error(y_test, Log_pred))\n",
    "print(\"MSE: \",metrics.mean_squared_error(y_test,Log_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test,Log_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_score = Logistic_Regression.score(X_test, y_test)\n",
    "LogisticRegression_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the DecisionTreeRegressor model to the dataset\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DecisionTree_Regressor = DecisionTreeRegressor(random_state = 0)\n",
    "DecisionTree_Regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.0125\n",
      "MSE:  0.0125\n",
      "RMSE:  0.11180339887498948\n"
     ]
    }
   ],
   "source": [
    "# Predicting a new result with the Decision Tree Regression\n",
    "DT_pred = DecisionTree_Regressor.predict(X_test)\n",
    "\n",
    "print(\"MAE: \",metrics.mean_absolute_error(y_test, DT_pred))\n",
    "print(\"MSE: \",metrics.mean_squared_error(y_test, DT_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, DT_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0],\n",
       "       [ 1, 51]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree_confusion_matrix = confusion_matrix(y_test, DT_pred) \n",
    "DecisionTree_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945054945054945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree_score = DecisionTree_Regressor.score(X_test, y_test)\n",
    "DecisionTree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RandomForestRegressor model to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RandomForest_Regressor = RandomForestRegressor(random_state = 0)\n",
    "RandomForest_Regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.0125\n",
      "MSE:  0.0125\n",
      "RMSE:  0.11180339887498948\n"
     ]
    }
   ],
   "source": [
    "# Predicting a new result with the RandomForestRegressor\n",
    "RF_pred = RandomForest_Regressor.predict(X_test)\n",
    "\n",
    "print(\"MAE: \",metrics.mean_absolute_error(y_test, RF_pred))\n",
    "print(\"MSE: \",metrics.mean_squared_error(y_test, RF_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, RF_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0],\n",
       "       [ 1, 51]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_confusion_matrix = confusion_matrix(y_test, RF_pred) \n",
    "RandomForest_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945054945054945"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_score = RandomForest_Regressor.score(X_test, y_test)\n",
    "RandomForest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Multilinear_model=LinearRegression()\n",
    "Multilinear_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2644836477908399\n",
      "MSE:  0.09642933318410943\n",
      "RMSE:  0.3105307282445804\n"
     ]
    }
   ],
   "source": [
    "# Predicting a new result with the LinearRegression\n",
    "ML_pred = Multilinear_model.predict(X_test)\n",
    "\n",
    "print(\"MAE: \",metrics.mean_absolute_error(y_test, ML_pred))\n",
    "print(\"MSE: \",metrics.mean_squared_error(y_test, ML_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, ML_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5761347991907277"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multilinear_score = Multilinear_model.score(X_test, y_test)\n",
    "Multilinear_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "SupportVectorRegression = SVR()\n",
    "SupportVectorRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.09382720300781053\n",
      "MSE:  0.02275556326645812\n",
      "RMSE:  0.1508494722114006\n"
     ]
    }
   ],
   "source": [
    "SVR_pred = SupportVectorRegression.predict(X_test)\n",
    "\n",
    "print(\"MAE: \",metrics.mean_absolute_error(y_test, SVR_pred))\n",
    "print(\"MSE: \",metrics.mean_squared_error(y_test, SVR_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, SVR_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999755460815028"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupportVector_score= SupportVectorRegression.score(X_test, y_test)\n",
    "SupportVector_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA - Accuracy over different Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression        \t:  98.75\n",
      "RMSE \t\t\t\t:  0.112\n",
      "\n",
      "Decision Tree Regression \t:  94.51\n",
      "RMSE \t\t\t\t:  0.112\n",
      "\n",
      "Random Forest Regression \t:  94.51\n",
      "RMSE \t\t\t\t:  0.112\n",
      "\n",
      "Multiple Linear Regression\t:  57.61\n",
      "RMSE \t\t\t\t:  0.311\n",
      "\n",
      "Support Vector Regression\t:  90.0\n",
      "RMSE \t\t\t\t:  0.151\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression        \\t: \", round(LogisticRegression_score*100, 2))\n",
    "print(\"RMSE \\t\\t\\t\\t: \", round(np.sqrt(metrics.mean_squared_error(y_test, Log_pred)), 3))\n",
    "print(\"\\nDecision Tree Regression \\t: \", round(DecisionTree_score*100, 2))\n",
    "print(\"RMSE \\t\\t\\t\\t: \", round(np.sqrt(metrics.mean_squared_error(y_test, DT_pred)), 3))\n",
    "print(\"\\nRandom Forest Regression \\t: \", round(RandomForest_score*100, 2))\n",
    "print(\"RMSE \\t\\t\\t\\t: \", round(np.sqrt(metrics.mean_squared_error(y_test, RF_pred)), 3))\n",
    "print(\"\\nMultiple Linear Regression\\t: \", round(Multilinear_score*100, 2))\n",
    "print(\"RMSE \\t\\t\\t\\t: \", round(np.sqrt(metrics.mean_squared_error(y_test, ML_pred)), 3))\n",
    "print(\"\\nSupport Vector Regression\\t: \", round(SupportVector_score*100, 2))\n",
    "print(\"RMSE \\t\\t\\t\\t: \", round(np.sqrt(metrics.mean_squared_error(y_test, SVR_pred)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Principal Component Analysis (PCA)\n",
    "\n",
    "   - 400 x 24 High-dimensional space was projected to 400 x 2 lower-dimensional sub-space without losing \n",
    "    \n",
    "    \n",
    "   - The accuracy of the Individual model differs based on our Feature selections.\n",
    "   \n",
    "   \n",
    "   - Dimensionality reduction accuracy may differ from Correlation and other feature selection techniques in machine learning (Filter, Wrapper,  Embedded, Hybrid) \n",
    "   \n",
    "   \n",
    "   - Excluding Multiple-Linear Regression rest of all the Regression models having 90+ accuracy percentage.\n",
    "   \n",
    "   \n",
    "    . Logistic Regression       :  98.75             \n",
    "    . Decision Tree Regression \t:  94.51             \n",
    "    . Random Forest Regression \t:  94.51            \n",
    "    . Support Vector Regression\t:  90.0    \n",
    "    \n",
    "    \n",
    "   - Excluding Multiple-Linear Regression rest of all the Regression models having 90+ accuracy percentage.\n",
    "   \n",
    "   \n",
    "   - Logistic, Decision Tree, Random Forest Regression giving best RMSE points.\n",
    "   \n",
    "   \n",
    "   - PCA is boosting the accuracy values, n_components and dataset's are playing significant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
